{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b06892",
   "metadata": {},
   "source": [
    "# Introducción a Pytorch\n",
    "\n",
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f42c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio scikit-learn  # (si hace falta)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)  # reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74546da",
   "metadata": {},
   "source": [
    "# Datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69295df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)     # CrossEntropyLoss espera long\n",
    "X_val   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val   = torch.tensor(y_val, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y, s=10)\n",
    "plt.title(\"Dos lunas (datos sintéticos)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff9622",
   "metadata": {},
   "source": [
    "# Propagación hacia adelante (forward)\n",
    "\n",
    "## 1. Forward “a mano” con tensores (ilustra el cálculo)\n",
    "\n",
    "Definimos pesos aleatorios y aplicamos: X -> capa oculta -> ReLU -> salida (logits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones\n",
    "in_features = 2\n",
    "hidden = 16\n",
    "out_features = 2  # dos clases\n",
    "\n",
    "# Inicialización aleatoria (por defecto ~N(0,1) escalado según init de PyTorch si usas nn.Linear;\n",
    "# aquí lo haremos explícito con torch.randn)\n",
    "W1 = torch.randn(in_features, hidden, dtype=torch.float32) * 0.1\n",
    "b1 = torch.zeros(hidden, dtype=torch.float32)\n",
    "\n",
    "W2 = torch.randn(hidden, out_features, dtype=torch.float32) * 0.1\n",
    "b2 = torch.zeros(out_features, dtype=torch.float32)\n",
    "\n",
    "# Forward manual (sin autograd por ahora, solo para ver el paso hacia adelante)\n",
    "def forward_manual(X):\n",
    "    z1 = X @ W1 + b1          # capa lineal 1\n",
    "    h1 = F.relu(z1)           # activación\n",
    "    logits = h1 @ W2 + b2     # capa lineal 2\n",
    "    return logits\n",
    "\n",
    "logits0 = forward_manual(X_train)     # [N, 2]\n",
    "print(\"Logits iniciales (primeras 5 filas):\\n\", logits0[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf6049d",
   "metadata": {},
   "source": [
    "Pérdida inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss0 = loss_fn(logits0, y_train)\n",
    "print(\"Pérdida inicial (sin entrenar):\", float(loss0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41c9ed",
   "metadata": {},
   "source": [
    "## 2. Forward usando un nn.Module (lo normal en PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features=2, hidden=16, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden)  # inicializa pesos aleatoriamente\n",
    "        self.fc2 = nn.Linear(hidden, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # logits (sin softmax para usar CrossEntropyLoss)\n",
    "        return x\n",
    "\n",
    "net = MLP(in_features=2, hidden=16, out_features=2)\n",
    "logits = net(X_train)           # forward\n",
    "loss = loss_fn(logits, y_train) # pérdida inicial\n",
    "print(\"Pérdida inicial (nn.Module):\", float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51c96c",
   "metadata": {},
   "source": [
    "# Propagación hacia atrás y optimización\n",
    "\n",
    "El ciclo de entrenamiento en PyTorch siempre sigue estos pasos:\n",
    "\n",
    "1. `optimizer.zero_grad()` — limpiar gradientes acumulados\n",
    "2. `logits = net(X_batch)` — **forward**\n",
    "3. `loss = loss_fn(logits, y_batch)` — calcular pérdida\n",
    "4. `loss.backward()` — **backward** (autograd calcula ∂loss/∂θ)\n",
    "5. `optimizer.step()` — **actualiza** parámetros con el optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)  # también puedes usar Adam\n",
    "\n",
    "def accuracy(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        pred = model(X).argmax(dim=1)\n",
    "        return (pred == y).float().mean().item()\n",
    "\n",
    "print(\"Acc (antes):\", accuracy(net, X_val, y_val))\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    logits = net(X_train)\n",
    "    loss = loss_fn(logits, y_train)\n",
    "    loss.backward()          # calcula gradientes d(loss)/d(param)\n",
    "    optimizer.step()         # actualiza pesos\n",
    "\n",
    "    if (epoch+1) % 40 == 0:\n",
    "        acc_tr = accuracy(net, X_train, y_train)\n",
    "        acc_va = accuracy(net, X_val, y_val)\n",
    "        print(f\"Época {epoch+1:3d} | loss={loss.item():.4f} | acc_tr={acc_tr:.3f} | acc_val={acc_va:.3f}\")\n",
    "\n",
    "print(\"Acc (después):\", accuracy(net, X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90805b56",
   "metadata": {},
   "source": [
    "# Frontera de decisión visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd155863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Malla para visualizar la frontera de decisión\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, 300),\n",
    "    np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, 300)\n",
    ")\n",
    "grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z = net(grid).argmax(dim=1).reshape(xx.shape).numpy()\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X_val[:,0], X_val[:,1], c=y_val, s=10)\n",
    "plt.title(\"Frontera de decisión (modelo entrenado)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afa7dd",
   "metadata": {},
   "source": [
    "# Control exlpícito de la inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb416392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net = MLP()\n",
    "net.apply(init_weights)  # aplica tu init definida arriba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510a23d",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d9fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=0)\n",
    "\n",
    "# Control exlpícito de la inicialización\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a676177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso de Data loader de Pytorch\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "batch_size = 200\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d26ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_X, batch_y in train_loader:\n",
    "    print(batch_X.shape, batch_y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445edeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "itertrain = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c30f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch, ybatch = next(itertrain)\n",
    "print(xbatch.shape, ybatch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40061c",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación por lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6013bae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c8f2467ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio scikit-learn  # (si hace falta)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)  # reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322cd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=0)\n",
    "\n",
    "# Control exlpícito de la inicialización\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f51af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635dc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2213d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "y_val = torch.LongTensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4116a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df77f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la arquitectura de la red\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features=2, hidden=16, out_features=2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden)  # inicializa pesos aleatoriamente\n",
    "        self.fc2 = nn.Linear(hidden, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # logits (sin softmax para usar CrossEntropyLoss)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "515baf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(in_features=2, hidden=16, out_features=2)\n",
    "\n",
    "# Definimos funciones de pérdida y optimizador\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ff41d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epocha 1. Pérdida de validación: 0.6504035592079163\n",
      "Epocha 2. Pérdida de validación: 0.6388087272644043\n",
      "Epocha 3. Pérdida de validación: 0.6210969090461731\n",
      "Epocha 4. Pérdida de validación: 0.5987727046012878\n",
      "Epocha 5. Pérdida de validación: 0.5734470884005228\n",
      "Epocha 6. Pérdida de validación: 0.5475149552027384\n",
      "Epocha 7. Pérdida de validación: 0.5229825576146444\n",
      "Epocha 8. Pérdida de validación: 0.5018765131632487\n",
      "Epocha 9. Pérdida de validación: 0.48509566982587177\n",
      "Epocha 10. Pérdida de validación: 0.4726937214533488\n",
      "Epocha 11. Pérdida de validación: 0.46348222096761066\n",
      "Epocha 12. Pérdida de validación: 0.45579660932223004\n",
      "Epocha 13. Pérdida de validación: 0.44716615478197735\n",
      "Epocha 14. Pérdida de validación: 0.4368632634480794\n",
      "Epocha 15. Pérdida de validación: 0.4240368704001109\n",
      "Epocha 16. Pérdida de validación: 0.4086986879507701\n",
      "Epocha 17. Pérdida de validación: 0.39213764667510986\n",
      "Epocha 18. Pérdida de validación: 0.3759562472502391\n",
      "Epocha 19. Pérdida de validación: 0.3622449239095052\n",
      "Epocha 20. Pérdida de validación: 0.35260377327601117\n",
      "Epocha 21. Pérdida de validación: 0.34839460253715515\n",
      "Epocha 22. Pérdida de validación: 0.3506780167420705\n",
      "Epocha 23. Pérdida de validación: 0.35906744996706647\n",
      "Epocha 24. Pérdida de validación: 0.3724592427412669\n",
      "Epocha 25. Pérdida de validación: 0.38734309871991474\n",
      "Epocha 26. Pérdida de validación: 0.3997207581996918\n",
      "Epocha 27. Pérdida de validación: 0.40888933340708417\n",
      "Epocha 28. Pérdida de validación: 0.4126407504081726\n",
      "Epocha 29. Pérdida de validación: 0.41139442722002667\n",
      "Epocha 30. Pérdida de validación: 0.40629788239796955\n",
      "Epocha 31. Pérdida de validación: 0.39871375759442645\n",
      "Epocha 32. Pérdida de validación: 0.39051227768262226\n",
      "Epocha 33. Pérdida de validación: 0.384122093518575\n",
      "Epocha 34. Pérdida de validación: 0.38109023372332257\n",
      "Epocha 35. Pérdida de validación: 0.3824486931165059\n",
      "Epocha 36. Pérdida de validación: 0.3874928851922353\n",
      "Epocha 37. Pérdida de validación: 0.39608614643414813\n",
      "Epocha 38. Pérdida de validación: 0.40804389119148254\n",
      "Epocha 39. Pérdida de validación: 0.4192454218864441\n",
      "Epocha 40. Pérdida de validación: 0.4280545612176259\n",
      "Epocha 41. Pérdida de validación: 0.4349253276983897\n",
      "Epocha 42. Pérdida de validación: 0.43870819608370465\n",
      "Epocha 43. Pérdida de validación: 0.4395461678504944\n",
      "Epocha 44. Pérdida de validación: 0.43936235706011456\n",
      "Epocha 45. Pérdida de validación: 0.4406818648179372\n",
      "Epocha 46. Pérdida de validación: 0.4439426561196645\n",
      "Epocha 47. Pérdida de validación: 0.45145973563194275\n",
      "Epocha 48. Pérdida de validación: 0.4593977133433024\n",
      "Epocha 49. Pérdida de validación: 0.46486379702885944\n",
      "Epocha 50. Pérdida de validación: 0.46175729235013324\n",
      "Epocha 51. Pérdida de validación: 0.44549209872881573\n",
      "Epocha 52. Pérdida de validación: 0.4197421868642171\n",
      "Epocha 53. Pérdida de validación: 0.39069196581840515\n",
      "Epocha 54. Pérdida de validación: 0.3666354219118754\n",
      "Epocha 55. Pérdida de validación: 0.3519838750362396\n",
      "Epocha 56. Pérdida de validación: 0.3460363248984019\n",
      "Epocha 57. Pérdida de validación: 0.34721288581689197\n",
      "Epocha 58. Pérdida de validación: 0.34927359223365784\n",
      "Epocha 59. Pérdida de validación: 0.3470930556456248\n",
      "Epocha 60. Pérdida de validación: 0.3384178578853607\n",
      "Epocha 61. Pérdida de validación: 0.3225046594937642\n",
      "Epocha 62. Pérdida de validación: 0.30107684930165607\n",
      "Epocha 63. Pérdida de validación: 0.28050337235132855\n",
      "Epocha 64. Pérdida de validación: 0.2666025559107463\n",
      "Epocha 65. Pérdida de validación: 0.26420316100120544\n",
      "Epocha 66. Pérdida de validación: 0.2737659513950348\n",
      "Epocha 67. Pérdida de validación: 0.28819404045740765\n",
      "Epocha 68. Pérdida de validación: 0.29372039437294006\n",
      "Epocha 69. Pérdida de validación: 0.2775843143463135\n",
      "Epocha 70. Pérdida de validación: 0.2462527851263682\n",
      "Epocha 71. Pérdida de validación: 0.21941560010115305\n",
      "Epocha 72. Pérdida de validación: 0.21007036169370016\n",
      "Epocha 73. Pérdida de validación: 0.2193291038274765\n",
      "Epocha 74. Pérdida de validación: 0.23738065361976624\n",
      "Epocha 75. Pérdida de validación: 0.24969362715880075\n",
      "Epocha 76. Pérdida de validación: 0.2422641714413961\n",
      "Epocha 77. Pérdida de validación: 0.2172328680753708\n",
      "Epocha 78. Pérdida de validación: 0.18731689949830374\n",
      "Epocha 79. Pérdida de validación: 0.17554356654485068\n",
      "Epocha 80. Pérdida de validación: 0.19860105216503143\n",
      "Epocha 81. Pérdida de validación: 0.23178384701410928\n",
      "Epocha 82. Pérdida de validación: 0.22597375512123108\n",
      "Epocha 83. Pérdida de validación: 0.18380859990914664\n",
      "Epocha 84. Pérdida de validación: 0.15744030475616455\n",
      "Epocha 85. Pérdida de validación: 0.1688768913348516\n",
      "Epocha 86. Pérdida de validación: 0.20082315802574158\n",
      "Epocha 87. Pérdida de validación: 0.22762669126192728\n",
      "Epocha 88. Pérdida de validación: 0.2324884831905365\n",
      "Epocha 89. Pérdida de validación: 0.21407069762547812\n",
      "Epocha 90. Pérdida de validación: 0.18382868667443594\n",
      "Epocha 91. Pérdida de validación: 0.1576984723409017\n",
      "Epocha 92. Pérdida de validación: 0.15386701126893362\n",
      "Epocha 93. Pérdida de validación: 0.1728076289097468\n",
      "Epocha 94. Pérdida de validación: 0.1974046379327774\n",
      "Epocha 95. Pérdida de validación: 0.20387226343154907\n",
      "Epocha 96. Pérdida de validación: 0.18701670070489249\n",
      "Epocha 97. Pérdida de validación: 0.16017629702885947\n",
      "Epocha 98. Pérdida de validación: 0.14380338788032532\n",
      "Epocha 99. Pérdida de validación: 0.1451264669497808\n",
      "Epocha 100. Pérdida de validación: 0.15990100800991058\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        logits = net(batch_X)           # forward\n",
    "        loss = loss_fn(logits, batch_y) # pérdida inicial\n",
    "        loss.backward()          # calcula gradientes d(loss)/d(param)\n",
    "        optimizer.step()         # actualiza pesos\n",
    "\n",
    "    loss_vals = []\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        logits = net(batch_X)\n",
    "        loss = loss_fn(logits, batch_y)\n",
    "        loss_vals.append(float(loss))\n",
    "    print(f\"Epocha {epoch+1}. Pérdida de validación:\", np.mean(loss_vals))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
